\chapter{Implementation}\label{ch:implementation}
Given the context and background of the IEEE 2030.5 protocol, and the high-level design decisions we've been required to make, we can discuss the technical design decisions present in our final implementation.

\section{Common Library}
The common library, \texttt{sep2\_common}, contains all functionality that we have determined to be common to both IEEE 2030.5 clients and servers.

\subsection{Resource Data Types}
The primary purpose of the common library is to provide Rust representations of resources, which are described precisely in an XSD.
Resources range from data that may be used by the electric utility, such as the current load of the device, to resource metadata, such as the rate at which a client should poll a server for a given resource, or what URI endpoint can be used to access a given resource, in the case of a Link resource.
In IEEE 2030.5, these data structures are separated into packages for each of the function sets.

Whilst IEEE 2030.5 makes no mention of the object oriented programming paradigm, OOP inheritance underpins the design of all resources. Data types use both multi-level and hierarchial inheritance.
For the purpose of having developers reuse code, many base types appear in the 'common' package; these are data types extended by many others.

\subsubsection{Representing Resources in Rust}
Rust, despite being influenced by OOP languages, does not posses the notion of a class, like in languages like C++ or Java. As such, Rust does not define shared behaviour of types through inheritance from a common parent class. 
Rather, shared behaviour is defined through traits. In this case, Rust shared behaviour refers solely to the methods that we can call on that type - the traits a type implements.

In this sense, Rust polymorphism does not concern itself with what a type is or what that type stores, it concerns itself only with the traits it possesses.

Traits themselves do support a form of inheritance. Traits can require that other traits be implemented for a given type. However, this does not change the fact that traits only represent behaviour - 
there is no way to have a data structure inherit the internal members of another.

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            pub trait SEResource {
                fn href(&self) -> Option<&str>;
            }
        \end{lstlisting}
        \caption{A Rust trait representing the IEEE 2030.5 "Resource" data type.}
    \end{center}
\end{figure}



\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            pub trait SEList: SEResource {
                fn all(&self) -> Uint32;
                fn results(&self) -> Uint32;
            }
        \end{lstlisting}
        \caption{A Rust trait representing the IEEE 2030.5 \texttt{List} data type.}
    \end{center}
\end{figure}

In Figure 6.2, we have a Rust trait that describes the behaviour of the List base type. All lists are resources, and thus we have a trait bound that all types implementing SEList must first implement the SEResource trait.

The prefix \texttt{SE} (for 'Smart Energy') simply differentiates the trait from the concrete type with the same name.

This is the extent of native inheritance in Rust. We can specify the exact behaviour of types that belong to a trait in detail, but we cannot influence how that behaviour is achieved.

\subsubsection{Emulating inheritance in Rust}

As a result, we're forced to emulate the inheritance of data structure members in Rust, of which there are two approaches:

\begin{itemize}
    \item Composite an instance of the base type into type definitions.
    \item Repeat all inherited members in type definitions.
\end{itemize}

Regardless of the approach, we would still not have have polymorphism using resource base-types as supertypes.
To allow for polymorphism a trait must be defined for each base-type. That trait must then be implemented for all types that extends that base type. 
This is unavoidable duplicate code - although Rust provides ways for which it can be generated at compile-time.

\subsubsection{Inheritance via Composition}

If we had implemented the first of the two approaches, we could have made use of an existing Rust library to reduce the amount of boilerplate required to implement polymorphism.
This library operates on the basis that inheritance can be replicated via composition. If a data type were to contain a member that implements a given trait, there is no reason for that outer struct to not be able to implement that trait by simply calling upon the underlying member.


\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            #[inheritable]
            pub trait SEResource {
                fn href(&self) -> Option<&str>;
            }

            pub struct Resource {
                href: Option<String>
            }

            impl SEResource for Resource {
                fn href(&self) -> Option<&str> {
                    self.href.as_str()
                }
            }
        \end{lstlisting}
        \label{fig:resinher}
        \caption{Rust code required to represent the IEEE 2030.5 "Resource" data type using 'inheritance-rs'.}
    \end{center}
\end{figure}

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            #[derive(Inheritance)]
            pub struct List {
                #[inherits(SEResource)]
                res: Resource,
                all: Uint32,
                results: Uint32,
            }
        \end{lstlisting}
        \label{fig:listinher}
        \caption{A Rust data type representing an IEEE 2030.5 \texttt{List} using 'inheritance-rs'.}
    \end{center}
\end{figure}


Figures 6.3 and 6.4 show how this library, \texttt{inheritance-rs} \cite[]{inheritancers} is used to reduce the boilerplate necessary to inherit data members. 
In Figure 6.3, we mark the SEResource trait as 'inheritable' and then implement that trait on a type that holds the necessary members, our bare minimum 'base' type. 
In Figure 6.4, we compose an instance of that base type into a type that would normally inherit from it. Then, we tell the library to generate the code, at compile time, that would allow List to implement the SEResource trait.
This generated code simply calls the underlying SEResourceObj member when the href function would be called on a list.

The major flaw in this approach is that for every single type that is used as a base type, a trait, and a base implementation of that trait needs to be written.
Given that there are just under 700 data types in the IEEE 2030.5 schema, we had to consider alternatives.


\subsubsection{XSD to Rust types}

If we were to implement the second approach, an existing Rust library can be used to automate the process of defining data types altogether.
This of course draws on the fact that the IEEE 2030.5 XSD is entirely self-contained, and follows XSD guidelines by W3C. As such, generating Rust data types from it is a reasonable approach.
One such way to automate this process would be to design and implement our own XSD parser and struct generator. Fortunately, we are not the first to require such a tool.

On the Rust public crates registry there are several XSD parsers, many of which existing to solve very similar problems; implementing standardised communication protocols in Rust.
However, for that reason, many of these implementations are developed until they meet the creators needs, at which point the tool is no longer maintained.

Of the most complete parsers, one particular implementation stands out. This crate supports multi-level and hierarchial inheritance and makes reasonable assumptions on the internal representations of primitive data types.
\texttt{xsd-parser-rs} by \texttt{Lumeo}, was created for use in their \texttt{Open Network Video Interface Forum Client}, software with requirements not dissimilar to that of IEEE 2030.5. \cite[]{xsdparserrs}

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            #[derive(Default, PartialEq, Debug, YaSerialize, YaDeserialize)]
            #[yaserde(namespace = "urn:ieee:std:2030.5:ns")]
            pub struct List {
                // The number specifying "all" of the items in the list. 
                // Required on a response to a GET, ignored otherwise.
                #[yaserde(attribute, rename = "all")]
                pub all: Uint32,
            
                // Indicates the number of items in this page of results.
                #[yaserde(attribute, rename = "results")]
                pub results: Uint32,
            
                // A reference to the resource address (URI). 
                // Required in a response to a GET, ignored otherwise.
                #[yaserde(attribute, rename = "href")]
                pub href: Option<String>,
            }
        \end{lstlisting}
        \label{fig:listauto}
        \caption{A Rust data type representing an IEEE 2030.5 \texttt{List} as generated by \texttt{xsd-parser-rs}.}
    \end{center}
\end{figure}

Figure 6.5 is what \texttt{xsd-parser-rs} produced for the List resource, without any modification. In this figure, it's parsed that the List type inherits from the Resource type, and included the href data member accordingly. It's also included the documentation as found in the schema.

Compared to inheritance in other languages, this has types include their parent type data members in their own type definitions.
Despite this, the type definitions are far more readable, and align more closely with the output of the client - inheritance is 'flattened' out.


\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            <List xmlns="urn:ieee:std:2030.5:ns" all="0" results=0" 
            href="/sample/list/uri" />
        \end{lstlisting}
        \label{fig:listxml}
        \caption{An XML representation of an IEEE 2030.5 \texttt{List} data type.}
    \end{center}
\end{figure}

Figure 6.6 shows the List data type were it serialised into XML.

\texttt{xsd-parser-rs} does not perfectly fit our needs. However, it is released under the MIT license, giving us the freedom to fork the library, modify it accordingly, and manually adjust the output as required. As part of our common library implementation we've:

\begin{itemize}
    \item Modified the tool to use the Rust Option type where the XSD specifies \texttt{minOccurs=0} and \texttt{maxOccurs=1}.
    \item Modified the tool to provide us with the names of all types in a type's inheritance tree.
    \item Modified the Derive output on all data types to automatically implement traits where useful.  
    \item Manually implemented Rust enums for all types that are integer enumerations.
    \item Manually implemented Rust \texttt{bitflags} for all integer bitmap types.
\end{itemize}

Due to the large amount of manual work required on the outputted code it is unlikely we will use \texttt{xsd-parser-rs} again, unless the XSD undergoes a major revision, and that major revision cannot be simply implemented with modern text replacement tools.

\subsubsection{Integer Bitmaps}
IEEE 2030.5, for the sake of efficiency, has resources encode many boolean values together in a single integer, a bitmap of booleans (colloquially a 'bitflag'). Whilst we must still maintain how these integers are stored internally, we have the opportunity to provide them in a more ergonomic interface. Thus, we use the \texttt{bitflags} crate, a popular Rust crate that wraps integers and provides convenience functions for comparing them (intersections, unions) and constructing them using enum-like syntax, whilst retaining support for bitwise operators \cite{bitflags}. 

\subsubsection{Resource Polymorphism}
As mentioned, we've used \texttt{xsd-parser-rs} to automate the process of resolving an inheritance tree in the XSD. This has enabled us to add polymorphism via base types to our implementation.

We add Resource polymorphism to our common library as it can be implemented relatively easily, and assists both ourselves in writing more generic code (such as the Event scheduler), and users of our library. One example is that users could now store all "Subscribable" resources in a single container, and use that as the set of active subscriptions.

Therefore, as part of \texttt{sep2\_common}, we define a set of Rust traits that mirror base type resources. 

Since IEEE 2030.5 does not use multiple inheritance (inheriting from more than one base type), if we were to mirror base types to traits exactly, we would be implementing a confusing level of redundancy in traits.
For example, \texttt{RespondableSubscribableIdentifiedObject} inherits from \texttt{RespondableSubscribableObject}, which provides it with three new fields that allow it to be 'identified'. Similarly, \texttt{RespondableIdentifiedObject} inherits from \texttt{RespondableObject}, but provides it with the same Identified fields. In this example, Resources become 'identified' in two different ways. Rather than have two traits that provide the same behaviour, but with two different supertraits, we simplify and provide a single \texttt{SEIdentifiedObject} trait. We do this for all such redundant definitions of fields.

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            trait SEIdentifiedObject: SEResource {
                fn mrid(&self) -> &MRIDType;
                fn description(&self) -> Option<&String32>;
                fn version(&self) -> Option<VersionType>;
            }
        \end{lstlisting}
        \label{fig:identtrait}
        \caption{Implementation of the IdentifiedObject trait.}
    \end{center}
\end{figure}

To implement these traits for all relevant types we use Rust's procedural macros - Rust code that runs at compile time producing more code to be compiled. A straight-forward implementation gives us the ability to derive any of these traits on a type that possesses all the required fields.

Manually adding these Derive annotations to all our data types would be extremely time consuming, and is unfeasible. Instead, we use our \texttt{xsd-parser-rs} fork to evaluate all the inheritance in the inheritance tree of a specific type, and use it to automate this process entirely. 

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            #[derive(
                SERandomizableEvent,
                SEEvent,
                SERespondableSubscribableIdentifiedObject,
                SEIdentifiedObject,
                SESubscribableResource,
                SERespondableResource,
                SEResource,
            )]
            struct EndDeviceControl { ... }
        \end{lstlisting}
        \label{fig:edctraits}
        \caption{The output of the modified \texttt{xsd-parser-rs} for \texttt{EndDeviceControl}.}
    \end{center}
\end{figure}

The result is all IEEE 2030.5 resources include trait implementations defining behaviour shared between them. 

\subsection{Resource Serialisation \& Deserialisation}
IEEE 2030.5 resources can be sent as their XML representations over HTTP. This means our common library requires the ability to serialise and deserialise resources to and from the appropriate XML.
This means HTTP requests containing resources are sent with the \texttt{Content-Type} header set to \texttt{application/sep+xml}.

On the public Rust crates registry, there exists a popular XML serialisation and serialisation library purpose built for use in embedded communication protocols called \texttt{YaSerde} \cite[]{YaSerde}.
Despite being developed by different teams, the syntax to use \texttt{YaSerde} on Rust data types is auto-generated by \texttt{xsd-parser-rs}, making it ideal for our use case.

Referring again to Figure 6.5, we see \texttt{xsd-parser-rs} has qualified our struct with the appropriate namespace, such that YaSerde serialisation will include it, and deserialisation will expect it.
Furthermore, names of data members have been specified as attributes, rather than child elements in the resulting XML; determined by the parser as per the XSD.
Figure 6.6 is an example of what the List type looks like when serialised to XML.

\texttt{YaSerde} does not perfectly fit our needs. However, it is also released under the MIT license, giving us the freedom to fork it, and add our required functionality.
As part of our work we've modified \texttt{YaSerde} (\texttt{SEPSerde}) in order to:

\begin{itemize}
    \item Serialise Rust enums as their underlying integer representations.
    \item Allow for Rust trait objects (dynamic dispatch) to be created on the serialise and deserialise traits.
    \item Serialise and deserialise IEEE 2030.5 \texttt{HexBinary} primitives as hexadecimal with an even number of digits. 
    \item Allow \texttt{bitflags} generated bitmaps to be serialised and deserialised.
    \item Allow for data types that use Rust generics to be serialised and deserialised (Notification \& NotificationList).
\end{itemize}

All done without requiring a manual per-type implementation.

\subsubsection{Notification}
The 'Notification' resource is a container for delivering resources to clients via the Subscription / Notification method. This means a Notification resource is generic, it contains some other resource as one of it's fields. To represent this as a type, we use Rust generics, where the generic type is bound by the 'SEResource' trait we've defined.

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            struct Notification<T: SEResource> {
                resource: Option<T>,
                ...
            }
        \end{lstlisting}
        \label{fig:notifgeneric}
        \caption{Notification resource implemented using Rust generics.}
    \end{center}
\end{figure}

This type representation uses Rust's monomorphisation, and therefore it being generic has no runtime overhead.

However, this poses some challenges for \texttt{YaSerde} which was not written with this sort of use case in mind. Even more so, the XML representation of a Notification resource is unique, in terms of how it expresses the type of the inner resource.

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
        <Notification xmlns="urn:ieee:std:2030.5:ns" 
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
            <subscribedResource>/upt/0/mr/4/r</subscribedResource>
            <Resource xsi:type="Reading">
                <timePeriod>
                    <duration>0</duration>
                    <start>12987364</start>
                </timePeriod>
                <value>1001</value>
            </Resource>
            <status>0</status>
            <subscriptionURI>/edev/8/sub/5</subscriptionURI>
        </Notification>        
        \end{lstlisting}
        \label{fig:notifxml}
        \caption{Example Notification<Reading> resource from IEEE 2030.5.}
    \end{center}
\end{figure}

Figure 6.10 shows a Notification resource that contains a Reading resource. Of interest is that the inner resource is always contained in an XML element with the name "Resource", and the type of the inner resource is instead given by the 'type' attribute, provided by the \texttt{XMLSchema-Instance} namespace. 

The implication of this is not only do we need to modify \texttt{SEPSerde} to handle generic Rust types, but we also need a way to add this  \texttt{xsi:type} attribute accordingly.

When setting the \texttt{xsi:type} attribute, we note that we require the name of the resource as a string. This means for every resource we also need to somehow bundle along with it a string literal of the name of the type. We do this by having the procedural macro define a function that contains that string literal.

Throughout our implementation, we've also found additional use for this function, using it to provide the name of the resource as additional context when creating logs in generic functions.

In order to instruct \texttt{SEPSerde} to place this \texttt{xsi:type} attribute as required, we add a new procedural macro attribute to the library, \texttt{generic}.

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            #[derive(
                YaSerialize, YaDeserialize, SESubscriptionBase, SEResource,
            )]
            #[yaserde(
                namespace = "urn:ieee:std:2030.5:ns",
                namespace = "xsi: http://www.w3.org/2001/XMLSchema-instance"
            )]
            pub struct Notification<T: SEResource> {
                #[yaserde(rename = "Resource")]
                #[yaserde(generic)]
                pub resource: Option<T>,
                ...
            }    
        \end{lstlisting}
        \label{fig:notifimpl}
        \caption{Notification resource implementation.}
    \end{center}
\end{figure}

Figure 6.11 shows this in use. We append the additional namespace as required, and include the \texttt{generic} attribute to the resource field. The result is that an instance of a \texttt{Notification<T: SEResource>} serialises and deserialises successfully. 


\subsubsection{NotificationList}
Unlike the Notification resource, the NotificationList resource's purpose is more ambiguous. In IEEE 2030.5 a NotificationList resource is described as a "List of Notifications" and that it is a "List Resource that supports multiple types". This could be interpreted in a few ways:

\begin{itemize}
    \item Each Notification in a Notification List can contain a different inner resource.
    \item All Notifications in a NotificationList must contain the same resource.
    \item A NotificationList is a Notification of a List resource, where that List resource is split up into multiple individual notifications.
\end{itemize}

The latter two interpretations would lead themselves to the most trivial implementation, a NotificationList need simply have a single generic type. The first interpretation would be, as a result of Rust's type-system, very much non-trivial, and would require each Notification to store a SEResource trait object (dynamic dispatch), as to force each Notification within the list to have the same concrete type.
Fortunately, as mentioned in 5.2.1 we assume developers would want to use different routes for different notifications, making the first interpretation irrelevant, as all notifications on a single route will contain the same inner resource.

However, that does not yet clarify which of the latter two are correct. In any case, this is merely the behaviour of the NotificationList after being deserialised, and not something we as library developers need to worry about. For that reason we implement NotificationList as simply a list of Notifications, all with the same inner resource.

\subsubsection{Exploring Dynamic Deserialisation}
Dynamic deserialisation was a feature we explored implementing in our \texttt{YaSerde} fork; the ability to determine how a given XML string should be deserialised at runtime, instead of having to know at compile-time, as is required in the current implementation.

The protocol's WADL XML document outlines all the routes a IEEE 2030.5 server can provide, and what type of resource is expected on that route. Coupled with the assumption that library users implementing the Subscription / Notification mechanism will use different routes for different incoming resources, we can deduce that the type of all incoming XML resources can be determined at compile time, and thus the need to inspect Resources and determine how they should be deserialised at run-time isn't at all necessary. 

Regardless, as part of this thesis we explored how this might be accomplished in Rust, in order to determine if it would work to improve the ergonomics of our common library interface.

In order to have a Rust function that deserialise all valid resources, even if the type is not known, we require that the function returns a single concrete type. For this we could use trait objects, Rust dynamic dispatch, which has the function return a 'fat' pointer, which contains a pointer to the resource (usually on the heap) and pointer to the table containing function pointers for the corresponding trait, often called a 'virtual method table'. 

Implementing this function with a trait object return type would require a significant time investment, adjusting the existing \texttt{YaSerde} code to have it it return a \texttt{Box<T>} (heap allocated), instead of \texttt{T} (stack allocated).

An alternative to using trait objects would be to have a Rust tagged union (an enum) of all (141) top-level resource types. Every resource would therefore have the same concrete type once wrapped in that enum.

Regardless of the approach, we would also need to implement some form of data structure mapping the names of resources to code that deserialise based off the type of the resource - we could likely auto-generate this.

If a trait object was used, the return type of the function doesn't provide users with anything immediately useful, in order to inspect the contents of the resource, they would need to downcast the trait object to a concrete type, which requires them to first know the concrete type at compile-time, bringing us back to the original problem.

The Rust enum approach improves this situation. When combined with Rust match statements library users can filter to a concrete resource as needed. However, with 141 different resources it's likely this filtering would be very verbose. Given that client developers should know the type of all incoming resources at compile time, implementing this functionality ourselves would force library users to handle this filtering themselves, even if they don't necessarily require it.

For that reason, we won't be implementing any form of dynamic deserialisation. If users require any of the approaches we've discussed, they have the ability to implement it themselves, or more reasonably, switch to a dynamically typed language where this model can be more easily supported, as we saw in the \texttt{envoy-client}.

\subsection{List Ordering}
IEEE 2030.5 defines list resources as simply a list of resources that can be retrieved in a single request. For each list resource, the specification defines how the list should be ordered, which values should be used as keys, and the precedence of those keys. \cite{IEEE2030.5}

Therefore, for all resources that are used in a list we've implemented the Rust \texttt{Ord} trait, which defines a total order (as opposed to a partial order), that will be used when using default sort methods on the list itself. We store list resources in Rust \texttt{Vec}s.

Unfortunately, these keys are not described in any easily parsable way, and was instead implemented manually.

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            impl Ord for DERControl {
                fn cmp(&self, other: &Self) -> std::cmp::Ordering {
                    // Primary Key - primacy (ascending)
                    match self.interval.start.cmp(&other.interval.start) {
                        core::cmp::Ordering::Equal => {}
                        ord => return ord,
                    }
                    // Secondary Key - creationTime (descending)
                    match self.creation_time.cmp(&other.creation_time).reverse() {
                        core::cmp::Ordering::Equal => {}
                        ord => return ord,
                    }
                    // Tertiary Key - mRID (descending)
                    self.mrid.cmp(&other.mrid).reverse()
                }
            } 

            impl PartialOrd for DERControl {
                fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
                    Some(self.cmp(other))
                }
            }
        \end{lstlisting}
        \label{fig:dercord}
        \caption{Ordering implementation for the DERControl trait.}
    \end{center}
\end{figure}

Figure 6.12 shows our implementation of this, where we first implement a total order, and then use that to implement the required partial order (of note is that there is now no "None" case for the partial order).

To provide an ergonomic way for working with lists, and ensure lists are always sorted, we use our procedural macros to provide a common interface for working with list resources. 

List resources contain a Rust \texttt{Vec} internally, which can be pushed to directly, but does not retain the sortedness. Instead, we provide a \texttt{add} function on all lists that inserts and retains the required order. This function also updates the 'all' field of the resource (the length of the list), to ensure it remains consistent with the actual contents of the list. Similarly, we provide a \texttt{remove} function maintaining the same invariants. For all other, less common use cases, library users will be required to update the list invariants as necessary. 

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            pub trait SEList: SEResource {
                type Inner: Ord;
                fn all(&self) -> Uint32;
                fn all_mut(&mut self) -> &mut Uint32;
                fn results(&self) -> Uint32;
                fn results_mut(&mut self) -> &mut Uint32;
                fn list_as_slice(&self) -> &[Self::Inner];
                fn list_mut(&mut self) -> &mut Vec<Self::Inner>;
            
                /// Add an item to the contained list, maintaining invariants
                fn add(&mut self, item: Self::Inner) {
                    self.list_mut().push(item);
                    // 'very fast in cases where the slice is nearly sorted'
                    self.list_mut().sort();
                    *self.all_mut() = Uint32(self.all().get() + 1);
                }
                
                ///Remove an item from the contained list, maintaining invariants
                fn remove(&mut self, idx: usize) -> Self::Inner {
                    *self.all_mut() = Uint32(self.all().get() - 1);
                    self.list_mut().remove(idx)
                }
        \end{lstlisting}
        \label{fig:listtraitimpl}
        \caption{The SEList trait, with default add and remove methods.}
    \end{center}
\end{figure}

\subsection{CSIP-AUS}
Implemented in \texttt{sep2\_common} are the IEEE 2030.5 extensions required by CSIP-AUS. These take the form of two additional resources, and additional fields on a subset of existing resources. When extensions are used, IEEE 2030.5 requires that the XML namespace for the extension be included with the resource, and that extension specific fields be prefixed accordingly. For CSIP-AUS this is the \texttt{https://csipaus.org/ns} namespace, and the \texttt{csipaus} prefix  \cite{CSIPAus}.

We make CSIP-AUS extensions available behind the \texttt{csip\_aus} crate feature (compile flag). When activated, the Rust compiler adds the namespace to existing IEEE 2030.5 resources, and adds the prefix to their respective fields. It also makes the new resources available for use, also with the correct namespace and prefix. Using existing functionality of \texttt{YaSerde}, adding these extensions is straight-forward.

As per the Energy Queensland SEP2 Client Handbook, and the CSIP-AUS publication by ARENA, these resources, and our support for the client aggregation model, are the extent to which we, as library developers, can assist users in developing CSIP-AUS compliant clients \cite{sep2clienthandbook} \cite{CSIPAus}. 

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            #[yaserde(namespace = "urn:ieee:std:2030.5:ns")]
            #[cfg_attr(
                feature = "csip_aus",
                yaserde(namespace = "csipaus: https://csipaus.org/ns")
            )]
            pub struct DERCapability {
                /// Bitmap indicating the CSIP-AUS controls implemented
                #[cfg(feature = "csip_aus")]
                #[yaserde(rename = "doeModesSupported")]
                #[yaserde(
                    prefix = "csipaus", 
                    namespace = "csipaus: https://csipaus.org/ns"
                )]
                pub doe_modes_supported: DOEControlType,
                ...
            }
        \end{lstlisting}
        \label{fig:csipausimpl}
        \caption{DERCapability annotated with optional CSIP-AUS extensions.}
    \end{center}
\end{figure}

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            <EndDevice xmlns="urn:ieee:std:2030.5:ns" 
                       xmlns:csipaus="https://csipaus.org/ns">
                <changedTime>0</changedTime>
                <csipaus:ConnectionPointLink  href="/edev/1/cp" />
                <sFDI>0</sFDI>
            </EndDevice>
        \end{lstlisting}
        \label{fig:enddeviceconnpointxml}
        \caption{Example XML representation of an EndDevice resource with a CSIP-AUS ConnectionPointLink.}
    \end{center}
\end{figure}

Figure 6.15 shows the output of our common library when an EndDevice is constructed with a ConnectionPointLink resource, and when the \texttt{csip\_aus} compile flag is enabled.


\subsection{MRID Generation}
IEEE 2030.5 Servers and Clients are both capable of creating resources. Resources where multiple instances exist, and must be differentiated from one another, contain a "Master Resource Identifier" (MRID), a 128 bit integer that is globally unique.
As such, library users will require a way of reliably creating cryptographically unique MRIDs. One requirement of the MRIDs is that they contain a IANA Private Enterprise Number (PEN) in the least significant 32 bits.

For that reason, we provide users of our library with a function with the signature \texttt{fn mrid\_gen(pen\_id: u32) -> MRIDType} that produces a new MRID each time it's called.

IEEE 2030.5 requires that MRIDs are sufficiently cryptographically unique, such that the risk of an MRID collision is minimised. The EPRI C implementation defines an algorithm for generating MRIDs that ensures, at the very minimum, that two MRIDs produced by a single instance of the program will not collide, at least for the first $2^{32}$ MRIDs generated. It does this by using a global, mutable, atomic integer that increments each time an MRID is generated. Since EPRI was able to release their MRID generation algorithm as part of their library, we assume it's sufficient, and implement a very similar algorithm in Rust.

\begin{figure}[H]
    \begin{center}
        \begin{lstlisting}
            static MRID_COUNT: AtomicU32 = AtomicU32::new(0);

            fn mrid_gen(pen_id: u32) -> MRIDType {
                let id: u128 = /* Generate Random u128 */
                let time: u128 = /* Get Unix Timestamp */
                let count: u128 = /* Fetch and increment MRID_COUNT */
                HexBinary128(
                    time << 32 | id << 32 | 
                    count << 32 | pen_id as u128)
            }
        \end{lstlisting}
        \label{fig:mridgenalgo}
        \caption{Rust implementation of an MRID generator, inspired by EPRI's.}
    \end{center}
\end{figure}


Going forward, it would be ideal to calculate the possibility of a global collision with this algorithm, as to verify that it is sufficiently cryptographically unique. This is currently out of scope for this thesis.

\subsection{Testing}
\texttt{sep2\_common} is developed alongside a suite of tests, ensuring all resources can be serialised and deserialised, and that their XML representations adhere to IEEE 2030.5.

When running LLVM source-based coverage on \texttt{sep2\_common} alone, the \texttt{grcov} report claims we have 59\% coverage, or 1647 \slash 2791 lines of code covered by tests. The vast majority of the missing coverage is code from compile-time code generation from libraries other than ours. In the vast majority of cases, this code is already tested. Regardless, we strive to improve this figure going forward.

\subsubsection{MRID Generation}
We provide a test verifying that the PEN ID can be obtained from a given MRID using bitwise operators, and that there are no collisions when generating several million MRIDs on a single instance of the program. This is to be expected, as we use include a global, mutable counter in the final value.

\subsubsection{Testing SEPSerde}
As expected, by the nature of serialisation and deserialisation, we have no compile time guarantees either will succeed for a given data type.
Therefore, our first test suite for the common library is to test that all data types can be serialised \& deserialised successfully, and that it can be done without any data loss.

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            #[test]
            fn default_List() {
                let og = List::default();
                let new: List = deserialize(serialize(og).unwrap()).unwrap();
                assert_eq!(og, new);
            }
        \end{lstlisting}
        \label{fig:yaserdetest}
        \vspace{-10pt}
        \caption{A Rust test verifying that the IEEE 2030.5 List resource can be serialised \& deserialised.}
    \end{center}
\end{figure}

The logic for a test of this type can be succinctly expressed in Rust, as seen in Figure 6.17. 
This test takes advantage of the fact that all our resources are able to automatically implement the 'default' trait, and as such an instance of any resource can be instantiated with default values.
In Figure 6.17, we first perform this default instantiation, convert the resource to an XML string, and then convert the XML string back into our internal List representation. 
Finally, we check if the newly deserialised resource is equal to it's default.

For each resource, the only part of this test that differs is the name of the type. As such, we auto-generate this test for each resource, and include it in \texttt{sep2\_common}.

\subsubsection{XML Correctness}
The remainder of the common library will be tested by ensuring representations of resources are correct with respect to those defined in IEEE 2030.5.
These tests use the example XML resources provided as part of IEEE 2030.5 as a starting point, as they are more likely to be correct than resources we would write by hand. However, the scope of these examples is narrow, and we will be required to write our own going forward.

\section{Client Library}
The client library, \texttt{sep2\_client}, contains the remainder of our implementation, and provides an interface for interacting with IEEE 2030.5 servers, as well as interfaces for handling Event resources, the Time function set, and an implementation of the Subscription / Notification mechanism. 

\subsection{Asynchronous Programming}
As mentioned, our client library is an I/O bound application, and uses async Rust to most efficiently make use of available resources. async Rust is runtime-agnostic, and must be connected to an executor of asynchronous tasks. In order to make the most of that runtime asynchronous functions capable of yielding are to be used in place of standard, blocking, functions, such as for I/O, or creating mutual exclusion.

Our client library is therefore implemented using the \texttt{Tokio} runtime, the most popular Rust async runtime \cite{Tokio}. Tokio uses \texttt{epoll} on Linux, and provides asynchronous wrappers for Rust standard library I/O. Furthermore, being the most popular, it is the only runtime to be extended and provide the functionality we require for our Subscription / Notification function set. This is the \texttt{tokio\_openssl} crate.

The Tokio runtime operates on the basis that we as developers create 'tasks' that yield to one as required, in order to make progress, even on a single OS thread. The Tokio runtime is then able to distribute these tasks across available operating system threads to best handle the current workload. To use the runtime effectively we need only use async operations in place of blocking operations, and spawn tokio tasks to handle I/O bound operations.  Spawning a Tokio task is not dissimilar from spawning a thread in Rust, but as an asynchronous runtime, does not necessarily lead to an OS thread being created.

\subsection{Application Support}
In IEEE 2030.5, the Application Support function set includes:

\begin{itemize}
    \item "RESTful HTTP/1.1 application data exchange semantics".
    \item 'XML and/or EXI encoding as the data payload of RESTful operations'.
    \item "Authentication and encryption as HTTP over TLS " (Security Function Set).
\end{itemize}

\cite{IEEE2030.5}

As such, this function set relies on a correct implementation of other standardised functionality. We choose to implement these standards by leveraging well-tested \& open-source implementations of HTTP, XML, and TCP.

\subsubsection{XML}
IEEE 2030.5 resources are serialised to XML via our \texttt{sep2\_common} crate, which depends on our \texttt{YaSerde} fork, \texttt{SEPSerde}. Internally, this uses the \texttt{xml-rs} crate, an XML parser \& writer \cite{xmlrs}. This library was chosen to due it's emphasis on correctness. 

In our research we found many competing libraries sacrifice correctness and completeness for performance, or are built for a specific use case, and then no longer maintained \cite{xmlrsperformance}.
Going forward, it may be worthwhile to explore alternative XML libraries that can be substituted into \texttt{SEPSerde} with the goal of improving XML parsing and writing performance. 

\subsubsection{HTTP}
To communicate with IEEE 2030.5 servers using HTTP we use the very popular Rust \texttt{hyper} library, as it currently integrates best with our Security function set requirements, and provides us with adherence to HTTP/1.1. \cite{hyper}.

In section 7.3.1 we discuss alternatives to this, and why we'd like to move away from \texttt{hyper} in the future.

\subsubsection{TCP}
Clients and servers using HTTP/1.1 must use TCP. The most sensible approach to implementing TCP is to wrap the target operating system's sockets library. This is done for us by the Rust standard library. Additionally, when instantiating the client, users can set a \texttt{SO\_KEEPALIVE} duration value, which will then be passed to the underlying Linux sockets library.

\subsection{Security}
The security function set of IEEE 20305 involves "securing transactions between clients and servers" via HTTP over TLS, or more commonly referred to as HTTPS. IEEE 2030.5 mandates a variation of TLS, mTLS, be used. mTLS provides a mechanism for mutually authenticating clients and servers. 

The major constraint implementing the security function set is that "All devices SHALL support the \\ \texttt{TLS\_ECDHE\_ECDSA\_WITH\_AES\_128\_CCM\_8} cipher suite", and that the "ECC cipher suite SHALL use elliptic curve secp256r1" \cite{IEEE2030.5}.

IEEE 2030.5 does allow for additional cipher suites to be used, provided they "provide a cryptographic strength at least equivalent to the mandatory cipher suite" \cite{IEEE2030.5}.  As it stands, users wishing to add additional cipher suites are required to modify the source code of our library, though we do not rule out the possibility of providing an interface for setting additional cipher suites in the future.

Additionally, IEEE 2030.5 defines six classes of X509 certificates, each with different restrictions on how they are to be signed, and what  X509 certificate extensions they contain, and how they are to be set.

Our client library provides developers with a generic interface for meeting the requirements of the Security function set.

\subsubsection{TLS via OpenSSL}
To implement TLS, we use the publicly audited, and commonly used library OpenSSL. OpenSSL is a C library, for which there exist popular Rust bindings that provide a safe foreign function interface to the underlying C code \cite{openssl}. 

The HTTP library \texttt{hyper} doesn't natively support OpenSSL, but accepts a generic connector interface for use with any conforming external TLS configuration. To accommodate for this, we have OpenSSL generate a TLS config and use the \texttt{hyper\_openssl} library to wrap that configuration in a connector that can be understood by \texttt{hyper} \cite{hyperopenssl}. 

An OpenSSL TLS configuration is generated when a IEEE 2030.5 Client, capable of making HTTPS requests, is instantiated. To create an IEEE 2030.5 TLS configuration for use in a Client device, library users must provide:

\begin{itemize}
    \item Path to a IEEE 2030.5 "Device Certificate" or "Self-Signed Client Certificate" \texttt{.pem} file.
    \item Path to the certificate's corresponding private key \texttt{.pem} file.
    \item Path to a IEEE 2030.5 "Root certificate" (SERCA) \texttt{.pem} file. 
\end{itemize}

IEEE 2030.5 places one additional restriction on what certificate can be used in the Subscription / Notification mechanism, namely that "all hosts implementing server functionality SHALL use a device certificate".

The relevant details on these certificate types are in IEEE 2030.5 \texttt{6.11.8.3.3}, \texttt{6.11.8.4.3} and \texttt{6.11.8.2}. We require the path to the CA to be supplied as to not require developers to install the CA on the system.

Client instances restricted to performing requests via HTTP do not need to supply any certificates, they need only be supplied an absolute URI of the target server. \texttt{hyper} handles DNS resolution, and as such, a hostname can be used.

Figure 6.18 shows a HTTPS client being instantiated with the server's address, the necessary certificates and key, the default \texttt{SO\_KEEPALIVE} value, and the default poll 'tickrate' (see section 6.2.5)/  

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            let client = Client::new_https(
                "https://127.0.0.1:1337",
                "client_cert.pem",
                "client_private_key.pem",
                "serca.pem",
                None, /* Default SO_KEEPALIVE */
                None, /* Default polling tickrate */
            )
        \end{lstlisting}
        \label{fig:httpsclientexample}
        \vspace{-10pt}
        \caption{Example IEEE 2030.5 Client instantiation.}
    \end{center}
\end{figure}


\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            config.set_cipher_list("ECDHE-ECDSA-AES128-CCM8")?;
            config.set_certificate_file(cert_path, SslFiletype::PEM)?;
            config.set_private_key_file(pk_path, SslFiletype::PEM)?;
            config.set_ca_file(rootca_path)?;
        \end{lstlisting}
        \label{fig:tlsconfigexample}
        \vspace{-10pt}
        \caption{Steps necessary to create an IEEE 2030.5 TLS configuration using OpenSSL.}
    \end{center}
\end{figure}

Figure 6.19 shows how we use the client supplied certificates and key to create a TLS configuration using OpenSSL. We note that OpenSSL supports the \texttt{ECDHE-ECDSA-AES128-CCM8} cipher suite.

\subsubsection{X509 Parsing \& Validation}
Additionally, we provide an interface for library users to verify that the provided X509 certificates adhere to the specification - that they contain the necessary extensions and fields. OpenSSL provides this functionality, however the Rust FFI bindings we use currently do not expose the corresponding API. Rather than write unsafe Rust FFI, and possibly introduce undefined behaviour to our library, we simply defer to the \texttt{X509-Parser} library, which lets us check these conditions efficiently \cite{x509parser}.

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            fn check_device_cert(cert: impl AsRef<Path>) -> Result<()>;
            fn check_self_signed_cert(cert: impl AsRef<Path>) -> Result<()>;
            fn check_ca(cert_path: impl AsRef<Path>) -> Result<()>;
        \end{lstlisting}
        \label{fig:certvalidinterface}
        \vspace{-10pt}
        \caption{IEEE 2030.5 certificate validation interface.}
    \end{center}
\end{figure}

We distinguish between IEEE 2030.5 'device certificates', and 'self signed client certificates', as they have different requirements. The Subscription / Notification mechanism, as discussed later, forbids the use of the latter.

\subsection{Core Client Functionality}
The core functionality of our IEEE 2030.5 client library is providing users with an interface for interacting with IEEE 2030.5 servers - creating and sending HTTP requests.
Our interface uses Rust's type system to ensure the contents of POST and PUT requests contain valid Resources, and that the contents of Responses to client GET requests also contain valid XML resources.

For all outgoing requests, our library also ensures spec adherence in terms of required HTTP headers. 

\begin{itemize}
    \item GET requests contain an \texttt{Accept} header, specifying that the body of the response should be \texttt{application/sep+xml}.
    \item PUT and POST requests contain appropriately set \texttt{Content-Length} and \texttt{Content-Type} headers.
    \item All outgoing requests also include the required date header, formatted as specified in RFC 7231, with appropriate accommodations for the Time function set  \cite{rfc7231}.
\end{itemize}


\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            async fn get<R: SEResource>(&self, path: &str) 
                -> Result<R>;
            async fn post<R: SEResource>(&self, path: &str, resource: &R) 
                -> Result<SEPResponse>;
            async fn put<R: SEResource>(&self, path: &str, resource: &R) 
                -> Result<SEPResponse>;
            async fn delete(&self, path: &str) 
                -> Result<SEPResponse>;
        \end{lstlisting}
        \label{fig:clientrequestinterface}
        \vspace{-10pt}
        \caption{Core client functionality interface.}
    \end{center}
\end{figure}

Once a client is instantiated, Figure 6.20 shows the functions operating on an instance of a client (\texttt{\&self}) for making requests. A generic \texttt{<R: SEResource>} parameter on these function signatures requires that the library user specify the type provided, as to determine how to serialise and deserialise. This need not be explicit, as Rust is able to infer this from the context.

For all these functions we automate error handling on behalf of the library user. Without knowing exact client use cases it's difficult to determine what level of error transparency they will require. As such, we make some assumptions on what information is and isn't useful.

\begin{itemize}
    \item For GET requests, we return an error if the request could not be made for any reason OR if the returned Resource body could not be deserialised into the provided type successfully.
    \item For POST, PUT and DELETE we only return an error if the actual request failed to send, or if there was no response from the server. In all other cases a value of the SEPResponse enum is returned.
\end{itemize}

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            enum SEPResponse {
                /// HTTP 201 w/ Location header value, if it exists
                /// 2030.5-2018 - 5.5.2.4
                Created(Option<String>),
                /// HTTP 204
                /// 2030.5-2018 - 5.5.2.5
                NoContent,
                /// HTTP 400 
                /// 2030.5-2018 - 5.5.2.9
                BadRequest(Option<Error>),
                /// HTTP 404 
                /// 2030.5-2018 - 5.5.2.11
                NotFound,
                /// HTTP 405 w/ Allow header value 
                /// 2030.5-2018 - 5.5.2.12
                MethodNotAllowed(String),
            }
        \end{lstlisting}
        \label{fig:sepresponse}
        \vspace{-10pt}
        \caption{Definition of the SEPResponse enum.}
    \end{center}
\end{figure}

Of special note, in Figure 6.21, is the \texttt{HTTP 400 Bad Request} SEPResponse. Per IEEE 2030.5, servers responding with \texttt{HTTP 400} will return an XML representation of an Error resource in the response body. When this occurs, our library will attempt to deserialise the error resource, and return it to the user. If that fails, the SEPResponse enum indicates it's absence using the Rust option type.

The IEEE 2030.5 successful request cases that can be returned are \texttt{201 Created} and \texttt{204 No Content}. Since the specification requires that \texttt{HTTP 201} responses contain an appropriate location header, we include that in the SEPResponse Created enum variant. The sam can be said for \texttt{HTTP 405 Method Not Allowed}, where servers must include an \texttt{Allow} header as part of the response, which we also include in our \texttt{MethodNotAllowed} variant.

Currently, this isn't exhaustive, though it includes all the successful request cases. For the vast majority of use cases this abstraction is sufficient. As part of our code release, we'll make library users aware of these deficiencies, and provide them with a plan for future enhancements.

In section 7.8 we discuss a design flaw with this current implementation, and why this interface might need to be adjusted going forward. In section 7.4 we discuss how we'll be able to improve the core client functionality, as a result of improvements to libraries in the Rust ecosystem.

\subsubsection{Event Response Interface}

Our library provides convenience functions for creating and sending response resources when given an event resource. This interface includes checks to ensure the provided response status matches up with that of the \texttt{ResponseRequired} field, and the requirements of the specific function set. As we'll discuss, the use of these are primarily automated via our Event schedules. We provide them directly to library users for completeness.

Each function sends the appropriate \texttt{SEResponse} resource to the server, returning an error if the inputs are invalid.


\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            async fn send_der_response(
                &self,
                lfdi: HexBinary160,
                event: &DERControl,
                status: ResponseStatus,
                time: SEPTime,
            ) -> Result<SEPResponse>;

            async fn send_drlc_response(
                &self,
                device: &SEDevice,
                event: &EndDeviceControl,
                status: ResponseStatus,
                time: SEPTime,
            ) -> Result<SEPResponse>;

            async fn send_pricing_response(
                &self,
                lfdi: HexBinary160,
                event: &TimeTariffInterval,
                status: ResponseStatus,
                time: SEPTime,
            ) -> Result<SEPResponse>;

            async fn send_msg_response(
                &self,
                lfdi: HexBinary160,
                event: &TextMessage,
                status: ResponseStatus,
                time: SEPTime,
            ) -> Result<SEPResponse>;
        \end{lstlisting}
        \label{fig:sendresponsefunc}
        \vspace{-10pt}
        \caption{Interface for creating and sending response resources.}
    \end{center}
\end{figure}

\subsection{Resource Polling}
IEEE 2030.5 defines two methods by which clients can receive updates to resources. One of those methods is via polling, where clients make GET requests on a regular interval.

\subsubsection{Interface}
We provide users with an abstraction for easily creating these regularly occurring poll events.

This abstraction is accessible from any instantiated client capable of making requests.

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            async fn start_poll<T: SEResource>(
                &self,
                path: impl Into<String>,
                poll_rate: Option<Uint32>,
                callback: impl PollCallback<T>,
            );
            async fn force_polls(&self);
            async fn cancel_polls(&self);
        \end{lstlisting}
        \label{fig:pollinterface}
        \vspace{-10pt}
        \caption{Interface for creating and sending response resources.}
    \end{center}
\end{figure}

Figure 6.23 shows this interface. \texttt{start\_poll} is given a URI relative to the absolute server URI and a callback, and polls the resource at the given poll rate, or the IEEE 2030.5 default rate of 15 minutes. Each interval, it performs a GET request, and provides the deserialised resource to the callback. Since this is an automated background task users will only be notified of request failures via the (later discussed) logging we provide. Ideally, they would only start polling a route once they know it's valid.

We also provide a function for forcibly polling all tasks in the queue, and a function for cancelling all resource polling. Library users may want to forcibly poll all resources in the event they were operating without internet, and have regained connection. Library users may want to cancel all poll tasks when attempting a graceful shutdown, no longer aggregating on behalf of a specific device.

One flaw with the current design is that users cannot implement any form of error handling logic for when a retrieval fails. This is discussed further in section 7.8.

\subsubsection{Ergonomics}
When implementing this interface, we take into consideration it's ergonomics. Thus, we provide two ways for users to implement a polling callback.


\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            trait PollCallback<T: SEResource>: Clone + Send + Sync + 'static {
                async fn callback(&self, resource: T);
            }
        \end{lstlisting}
        \label{fig:polltrait}
        \vspace{-10pt}
        \caption{A Rust trait representing the behaviour of a Poll callback.}
    \end{center}
\end{figure}

The first method allows user to implement the trait in Figure 6.24 on a type, and then pass an instance of that type when starting the poll.
This is useful when users have some thread-safe mutable state they want to share between all poll tasks, as they can implement handlers for multiple resources on a type, and then pass the same underlying instance of the type to multiple poll handlers, and thus access that same state in each handler.


\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            impl<F, R, T: SEResource> PollCallback<T> for F
            where
                F: Fn(T) -> R + Send + Sync + Clone + 'static,
                R: Future<Output = ()> + Send + 'static,
            {
                async fn callback(&self, resource: T) {
                    Box::pin(self(resource)).await
                }
            }            
        \end{lstlisting}
        \label{fig:pollimplgen}
        \vspace{-10pt}
        \caption{Rust code generating implementations of the PollCallback trait for all applicable functions.}
    \end{center}
\end{figure}

The second method uses the Rust language feature that allows us to generate implementations of a Rust trait for all types that meet certain conditions. In Figure 6.25 we therefore implement the PollCallback trait for all async, single argument functions that accept a valid Resource, and return the unit type (synonymous for no return value).
This allows both function pointers to be used, and any thread-safe closure that does not capture any references to it's environment that last less than the length of the program.

The outcome of this is that we've produced an abstraction that places as few restrictions on the caller as is reasonably possible.

\subsubsection{Internals}
When implementing this interface, we must address the performance of the client, and it's ability to operate at scale. Client aggregators must be able to handle polling many resources on behalf of many clients.

To implement this we use the asynchronous sleep functions provided by \texttt{Tokio}, which yields a task until the next scheduled poll time. Tokio tasks, while slept, virtually very minimal overhead. Unfortunately, Tokio sleeps, much like Rust's threaded sleeps, do not make progress while the device itself is slept. 

Whilst our client library is primarily for use on servers operating under the client aggregation model, we do not want to limit use of the library to that model. IEEE 2030.5 refers to particular end-user energy devices as "sleepy devices", that spend the majority of their time in modes of low power consumption. Should our implementation rely on asynchronous sleeps, we risk that, under specific cases, clients experience unnecessarily elongated intervals between polling.

A naive implementation that addresses this would have each individual Tokio task (one for each polled resource) wake intermittently, and check if it's time to poll their resource. This would be introduce an unnecessary overhead of multiple tasks repeatedly waking and sleeping.

Our final implementation uses a poll job queue, implemented using a binary heap, that sorts jobs by their next scheduled poll time. Then, we use a single Tokio task that sleeps, and wakes, intermittently to check if it is time to poll the resource at the top of the queue. Once that time arrives, the resource is retrieved and the stored user callback is given the result. The next time to poll on the poll task is then updated before pushing the job to the back of the queue. This process is entirely asynchronous, if it is time to poll multiple resources, each request will be sent off without waiting for the previous to complete. 

For the sake of flexibility, giving end users control over this process, and for the sake of testing, we allow users to define the length of these intermittent sleep intervals when they instantiate the client, we refer to this duration as the 'tickrate' of the polling task, defined using the Rust \texttt{Duration} type. If not supplied, a default of a 10 minute interval is used.

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            type PollHandler =
                Box<dyn Fn() 
                    -> Pin<Box<dyn Future<Output = ()> 
                    + Send + 'static>> 
                    + Send + Sync + 'static>;

            struct PollJob {
                handler: PollHandler,
                interval: Duration,
                next: Instant,
            }

            type PollQueue = Arc<Mutex<BinaryHeap<PollJob>>>;

        \end{lstlisting}
        \label{fig:pollimplds}
        \vspace{-10pt}
        \caption{Rust types used in implementing asynchronous resource polling.}
    \end{center}
\end{figure}

Figure 6.26 shows the data structures used in our implementation. A \texttt{PollHandler} is simply an async function that takes zero arguments, and returns nothing. This function contains the user-supplied callback within. A \texttt{PollJob} couples this function with the poll rate duration and the timestamp at which the next poll should occur.
\texttt{PollQueue} is a thread-safe Binary Heap of these \texttt{PollJob} instances, sorted by their next poll timestamp.


\subsection{Subscription / Notification}
The second method IEEE 2030.5 defines for receiving updates to Resources is via Subscription / Notification.
Using this mechanism, a client runs it's own lightweight HTTP server, with predefined routes that servers POST updated resources to. Clients notify servers of these routes by first creating a Subscription resource on the server, where they set the \texttt{notificationURI} field to an absolute URI.

\subsubsection{Interface}
This mechanism is optional, and runs irrespective of an instance of a client capable of making HTTP requests. Therefore, we provide users with the \texttt{ClientNotifServer} type, which can be instantiated much like a client.

To instantiate a HTTPS \texttt{ClientNotifServer}, a developer must provide:

\begin{itemize}
    \item The IP address and port the server will listen on for TCP connections.
    \item Path to a IEEE 2030.5 "Device Certificate" \texttt{.pem} file.
    \item Path to the certificate's corresponding private key \texttt{.pem} file.
    \item Path to a IEEE 2030.5 "Root certificate" (SERCA) \texttt{.pem} file. 
\end{itemize}

To instantiate a HTTP \texttt{ClientNotifServer}, only the first is required.

Once created, library users can add routes to the server by specifying the relative path to listen on, and an appropriate callback. In this case, a callback is a function that accepts one argument, a \texttt{Notification<T>}, where \texttt{T} is some resource, and returns a \texttt{SEPResponse}, the same type discussed in 6.2.4. The SEPResponse returned is constructed into an appropriate HTTP response, and then returned.

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            async fn incmg_dera(notif: Notification<DERAvailability>)
                -> SEPResponse {
                println!("DERAvailability Received: {:?}", notif);
                SEPResponse::NoContent
            }
        \end{lstlisting}
        \label{fig:notiffn}
        \vspace{-10pt}
        \caption{Example callback function for use by the \texttt{ClientNotifServer}.}
    \end{center}
\end{figure}

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            let server = ClientNotifServer::new(
                "127.0.0.1:1338",
            )?
            .with_https("client_cert.pem",
            "client_private_key.pem",
            "serca.pem")?
            .add("/dera", incmg_dera)
            .add("/txtmsg,| notif: Notification<TextMessage> | {
                println!("Message Received: {:?}", notif);
                async move { SEPResponse::NoContent }
            }).run(signal::ctrl_c()).await;
        \end{lstlisting}
        \label{fig:notifroutes}
        \vspace{-10pt}
        \caption{Example instantiation and route creation on a \texttt{ClientNotifServer}.}
    \end{center}
\end{figure}

Figure 6.27 shows an implementation of a function that can be used as a route callback. In this case, the callback will have the notiification server respond with \texttt{HTTP 204 No Content}. Figure 6.28 shows this function used as the callback for HTTP requests on the "/dera" route. This figure also shows how a closure with an appropriate function signature can be used, and also how the server can be run. 
The run function accepts a generic argument, an event that completes in the future, that can be used to end the server. In this example we provide it with a Tokio \texttt{SIGINT} (CTRL+C) signal handler. Upon receiving that signal, the server will attempt a graceful shutdown.

\subsubsection{Ergonomics}
We place as few restrictions on the user of our Subscription / Notification mechanism as possible. Just as is done with resource polling, we allow users to implement a callback via a manual trait implementation, or by any function or closure with a matching function signature.

Our abstraction handles invalid HTTP requests, and responds accordingly, as per IEEE 2030.5, without any intervention.

\subsubsection{Internals}
To serve requests over HTTPS we once again use OpenSSL to generate a TLS configuration using the provided certificates and private key. To merge our TCP stream, created using a Tokio \texttt{TcpListener}, and our TLS configuration, into a single TLS Stream we require the \texttt{tokio\_openssl} crate \cite{tokioopenssl}. This stream can then be passed to \texttt{hyper} to serve the request.

From this, we are required to route incoming HTTP requests to the correct user-defined callback. The simple nature of the server, and lack of parametrized route names results in a straight-forward implementation.

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            type RouteHandler = Box<
            dyn Fn(&str) -> Pin<Box<dyn Future<Output = SEPResponse>
             + Send + 'static>>
             + Send
             + Sync
             + 'static
             >;

            struct Router {
                routes: HashMap<String, RouteHandler, ahash::RandomState>,
            }

        \end{lstlisting}
        \label{fig:routerimpl}
        \vspace{-10pt}
        \caption{Rust types used in implementing a concurrent HTTP router.}
    \end{center}
\end{figure}

Figure 6.29 shows that our implementation uses a \texttt{HashMap} from strings (routes) to stored callbacks. 

The default hashing algorithm chosen by the Rust standard library sacrifices performance in order to defend against \texttt{HashDoS} attacks, as it uses an implementation of \texttt{SipHash}. Our router hashmap is never modified once the server is started, and therefore any DOS attacks on a client notification server instance would not be mitigated by a more secure hashing algorithm.

Therefore, we use the hashing algorithm provided by \texttt{ahash}, which is significantly faster, yet less resistant to \texttt{HashDoS} attacks \cite{ahash} \cite{hashbrown}.

\subsection{Time}
All IEEE 2030.5 clients must implement the Time function set. They must be able to use the current time to set HTTP date headers, update last modified timestamps, and check if a given Event resource has started or ended. Clients must be able to synchronise their device time with that of an IEEE 2030.5 server. This is done by having Servers expose Time resources. In the event there are multiple servers exposing time resources, the specification allows clients to choose just one Time resource, with the most accurate time (accuracy is specified within the resource itself), and synchronise using that.

The exception to this are event schedules: "... devices SHALL use the Time resource from the same FunctionSetAssignments when executing the events from the associated Event-based function set." which implies clients must be able to synchronise time differently, depending on the event-based function set. \cite{IEEE2030.5}.

\subsubsection{Interface}
Our client library must provide a generic abstraction that allows developers to synchronise time globally, and per event-based function set.

Throughout IEEE 2030.5 Client development, timestamps are required in a variety of formats. To provide a convenient interface for converting between these formats, we provide users with a \texttt{SEPTime} abstraction, that wraps the existing Rust native \texttt{SystemTime}, and represents a single timestamp that can be compared. \texttt{SEPTime} can be converted into:

\begin{itemize}
    \item A Rust \texttt{u64} for internal comparisons.
    \item An IEEE 2030.5 \texttt{Int64} for Resource fields and attributes.
    \item An RFC 7231 HTTP Timestamp String via SystemTime and the \texttt{httpdate} crate \cite{httpdate}.
\end{itemize} 


\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            fn current_time() -> SEPTime;
            
            fn current_time_with_offset() -> SEPTime
            
            fn update_time_offset(time: Time);
        \end{lstlisting}
        \label{fig:timeinterface}
        \vspace{-10pt}
        \caption{Time function set interface.}
    \end{center}
\end{figure}

Figure 6.30 details the interface we provide. Users can supply a Time resource to \texttt{update\_time\_offset} and update the global time offset. All future calls to \texttt{current\_time\_with\_offset} will then be synchronised with that specific Time resource.

For event-based function set time synchronisation, a similar interface is present on Event schedules (Figure 6.31). Schedules can be provided a Time resource that will be used to determine the start and end time stamps of all events for that function set, as well as the HTTP Date header of automated schedule HTTP requests.

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            fn update_time(&mut self, time: Time);
        \end{lstlisting}
        \label{fig:eventtime}
        \vspace{-10pt}
        \caption{Function operating on an instance of a Schedule for synchronising time.}
    \end{center}
\end{figure}

\subsection{Event Schedules}
In IEEE 2030.5 some function sets employ the use of Event resources, resources that include a start timestamp, and a duration for which they are active. These event resources are exposed to clients with the intent the device take specific action during that interval. Servers have the ability to cancel those events by updating them, and supersede these events by exposing new ones before the event finishes. Clients communicate with servers about these Event resources by creating and sending Response resources (those that implement the \texttt{SEResponse} trait).

An exhaustive list of function sets utilising Event resources are:

\begin{itemize}
    \item Distributed Energy Resources.
    \item Demand Response and Load Control.
    \item Messaging.
    \item Pricing.
    \item Flow Reservation.
\end{itemize}

All Schedules share very similar implementations. They differ in:

\begin{itemize}
    \item What response status codes can be sent (defined in IEEE 2030.5 Table 27).
    \item Under what circumstances events supersede one another.
    \item Whether or not event start times and durations can be randomised.
\end{itemize}

\subsubsection{Interface}

For each of these function sets (excl. Flow Reservation) we produce a \texttt{Schedule} abstraction that acts as a black-box handler of events. It accepts instances of Event resources and whenever an event starts, ends, or is cancelled or superseded whilst active, the schedule calls the defined callback such that the client can apply the event to the relevant device(s), and determine the Response resource status to return to the server. In many cases, such as when resources are cancelled before starting, the client need not be informed, and the schedule is instead capable of determining the correct response status itself - creating and sending the response resource automatically.

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            trait Scheduler<E: SEEvent> {
                type Program;

                fn new(
                    client: Client,
                    device: Arc<RwLock<SEDevice>>,
                    handler: impl EventCallback<E>,
                    tickrate: Duration,
                ) -> Self;

                async fn add_event(&mut self, 
                                   event: E, program:
                                   &Self::Program, 
                                   server_id: u8);
            }
        \end{lstlisting}
        \label{fig:schedulertrait}
        \vspace{-10pt}
        \caption{Definition of the Scheduler trait.}
    \end{center}
\end{figure}

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            fn update_time(&mut self, time: Time);
            fn shutdown(&mut self);
        \end{lstlisting}
        \label{fig:schedulerimpl}
        \vspace{-10pt}
        \caption{Interface common to all schedules.}
    \end{center}
\end{figure}

Figure 6.32 and 6.33 show the interface common to all schedules. Each schedule is associated with the type of the Event resource, and the type of the associated Event program. The type of the associated program in our interface is inferred from the type of the Event resource.

To instantiate a schedule library users must supply a previously instantiated client, capable of making HTTP requests. Schedules must support multiple servers, whereas a \texttt{Client} instance pertains to a specific server. Therefore, we override the base URI in the \texttt{Client} instance when creating and sending automated responses from the schedule. For that reason, any \texttt{Client} instance can be used.

A thread-safe reference to our \texttt{SEDevice} abstraction is also required, as well as a callback to be called when the schedule needs to inform the client of event updates.

Schedules also take a duration value, determining the length of intermittent sleeps, addressing the same problem we discussed in 6.2.5. If not supplied, a default interval of 10 minutes is used.

One instantiated, events are added to the schedule via the \texttt{add\_event} function, which takes a copy of the event, a reference to the event's program, and some unique ID pertaining to the server that the event was sourced from. This function is designed to be called every time a copy of the event is retrieved, via polling, or as a notification. Every event contains a unique MRID, and successive calls for the same MRID will simply update the status of the event, if the server has cancelled it. 

If an event retrieved from a server has a status that differs from the schedule copy of the event, and that status is not cancelled, the client will log accordingly. In some cases this is expected, such as when working with events where the start-time is randomised on the client. In other cases such as when an event is marked as superseded on the server and is not locally, the client will log a warning.


We require that a reference to the Event's program is included in order to mark which program an Event was added from. This allows the schedule to send the "Event aborted due to alternate program event" response status, in Table 27 of IEEE 2030.5.

Similarly, we require that some unique 8 bit integer is provided as a form of server ID, as to mark internally which events were sourced from different servers. The, when an event from one server supersedes an event from another, we can send the "Event aborted due to alternate server event" response status, also in Table 27 \cite{IEEE2030.5}. 

Finally, we provide a function for cleaning up the Tokio tasks spawned by the Schedule, freeing all allocated resources. This currently requires the shutdown function to be manually called. In the future, we'd like to have it automatically be called when the Schedule is dropped, which is a straight-forward refactor.

\subsubsection{SEDevice Abstraction}

Responses to Events, auto-generated or otherwise, contain device-specific information. For all event function sets this is the device's short form identifier, and long form identifier. In the event of the Demand Response and Load Control function set, devices also return data representing their state, such as their applied load reduction value.
Furthermore, events should only be applied when the category of device the Event targets matches the category of the device.

To inform a given event schedule of all these variables, we provide library users with an abstraction that represents a singular IEEE 2030.5 end-user energy device. This is the \texttt{SEDevice} struct.
In addition to the data already mentioned, this struct contains an instance of an EndDevice resource, such that all information a developer may require when referring to a singular device is available under the singular type.

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            pub struct SEDevice {
                pub lfdi: HexBinary160,
                pub sfdi: SFDIType,
                pub edev: EndDevice,
                pub device_categories: DeviceCategoryType,
                #[cfg(feature = "drlc")]
                pub appliance_load_reduction: Option<ApplianceLoadReduction>,
                #[cfg(feature = "drlc")]
                pub applied_target_reduction: Option<AppliedTargetReduction>,
                #[cfg(feature = "drlc")]
                pub duty_cycle: Option<DutyCycle>,
                #[cfg(feature = "drlc")]
                pub offset: Option<Offset>,
                #[cfg(feature = "drlc")]
                pub override_duration: Option<Uint16>,
                #[cfg(feature = "drlc")]
                pub set_point: Option<SetPoint>,
            }
        \end{lstlisting}
        \label{fig:sedevicestruct}
        \vspace{-10pt}
        \caption{Definition of the SEDevice struct.}
    \end{center}
\end{figure}

Figure 6.34 shows the contents of this struct. For the sake of modularity, we use Rust compile flags to hide the DRLC function set specific fields when the DRLC schedule is not being used. 

\subsubsection{Ergonomics}
Once again, we place as few restrictions on the library user as possible. Users can implement a callback via a manual trait implementation, or by any function or closure with a matching function signature.

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            pub trait EventHandler<E: SEEvent>: Send + Sync + 'static {
                async fn event_update(&self, event: &EventInstance<E>) -> ResponseStatus;
            }
        \end{lstlisting}
        \label{fig:eventhandlertrait}
        \vspace{-10pt}
        \caption{Definition of the Scheduler trait.}
    \end{center}
\end{figure}

Figure 6.34 defines the trait containing this function signature. A single argument function that takes in an EventInstance, containing the corresponding event resource, and returns a ResponseStatus. 

The \texttt{EventInstance<E>} type provides users with a way to inspect the event, providing users with:

\begin{itemize}
    \item The current status, as a Rust enum.
    \item The underlying event resource.
    \item The primacy of the program.
    \item The start time and end time of the event, as a Unix timestamp.
    \item The corresponding program MRID.
    \item The user-defined server ID.
\end{itemize}

When determining the ResponseStatus to return, library users need only to refer to Table 27 of the specification.

If the returned status implies the client device is opting out of the event, the scheduler also knows to mark the event as cancelled internally. In the event an event is superseded whilst active, our scheduler would have more information on what response to send to the server, and in that case the provided response status is ignored.

Since these cases are non-trivial, we provide an explanation of the behaviour of the callback as part of our library documentation.

\subsubsection{Internals}
All implemented schedules share the same core implementation. \texttt{EventInstance}s are stored in a hashmap, and the unique event MRID is used as a key into the hashmap. This gives us constant time lookups for events, and ensures a schedule cannot store duplicate events. Notably, unlike the hashmap used in the Subscription / Notification mechanism, our \texttt{EventsMap} uses the default, more HashDoS resistant, hashing algorithm. We make this decision as this hashmap does grow as the schedule runs, and MRIDs are technically provided as external input, making the possibility of a \texttt{HashDoS} attack possible, such as if resources were not retrieved (or sent) securely.
Realistically, this is perhaps an overly cautious measure; \texttt{aHash} still provides resistance to \texttt{HashDoS} attacks.

\begin{figure}[h]
    \begin{center}
        \begin{lstlisting}
            type EventsMap<E> = HashMap<MRIDType, EventInstance<E>>;

            struct Events<E>
            where
                E: SEEvent,
            {
                map: EventsMap<E>,
                next_start: Option<(i64, MRIDType)>,
                next_end: Option<(i64, MRIDType)>,
            }
        \end{lstlisting}
        \label{fig:eventmapimpl}
        \vspace{-10pt}
        \caption{Internal Events data structure.}
    \end{center}
\end{figure}

Figure 6.36 shows our wrapper around this hashmap that provides two values that act as hashmap invariants. These invariants store the time, and the MRID of the next event to start and the next event to end, or \texttt{None} if there are no events waiting to start or end. When instantiated, a schedule creates two Tokio tasks that sleep intermittently until it's time for an event to start. 

This \texttt{Events} wrapper is designed with the intention of minimizing the overhead when a Tokio task wakes from sleep and checks if it's time for the next event to start or end, it would only need to read a single value.

When these tasks find that an event should be started or ended, it updates it's status, notifies the client via the callback and uses the output of the callback to send a response to the server. When constructing a response, the schedule uses the data stored in the \texttt{SEDevice} instance it was passed, and uses the last Time resource provided to it via \texttt{update\_time}.

Finally, as to avoid our hashmap of events growing endlessly as the program runs, we have a third Tokio task act as a form of garbage collection, deleting cancelled or superseded events if they have not been updated for an extended period of time. Currently, this is configured at a week, but should be adjusted in the future as necessary, or provided as a configuration option.

The remainder of the schedule implementation differs for each function set. We've attempted to eliminate as much duplicate code as possible, however, we've been somewhat unsuccessful. Each schedule behaves sufficiently different to each other such that any further improvements would be pushing the boundaries of what is currently possible in Rust.

\subsubsection{DER}
The DER function set extends our core schedule implementation with events that can supersede one another, and a set of rules defining how and when this occurs. Therefore when an event is added to a DER schedule, it compares it with all other events in the schedule, and determines if it supersedes, or if it is superseded by another. 

We determine if two \texttt{DERControl} instances supersede by checking if hey both target the same hardware controls (the fields of DERControlBase) and if their active time periods overlap. If this is the case, the superseding event is the one with the lower program primacy, or if their primacies are the same, the event with the latest creation timestamp.

If an event is superseded and active, the user-defined callback is called, and the appropriate response to the server created and sent, as per Table 27, including the necessary comparisons between program MRIDs and server IDs.

We are also required to handle the case where an event is superseded by another, and then the superseding event is cancelled before the superseded event would start. To handle this we store, for each event, a list of MRIDs corresponding to events that supersede it. When an event is cancelled, it's removed from all those lists. Any superseded events that would not have started yet with an empty list can therefore be un-superseded.
This behaviour isn't explicitly mentioned in the specification, but follows naturally from the given rules. Additionally, this behaviour is implemented by EPRI C in their library.

DER events are 'randomizable' events. Therefore, when adding them to our Schedule we first determine their start time and interval with a random offset within the given range.

Since DERControl events apply only to specific device categories, we check if there is an intersection between the event targeted categories, and the categories set in \texttt{SEDevice}.

Finally, the interface we defined in Figure 6.22 is responsible for checking that a valid response can be constructed from a ResponseStatus and Event, and that it adheres to Table 27. If this is not the case, and an automated response cannot be made for any reason, the schedule will log accordingly.

\subsubsection{DRLC}
The DRLC function set schedule operates near identically to the DER schedule, with different types, and one difference in behaviour. They both exhibit 'direct control' over a device, and as such, only one event can be active at any given point in time.

Unlike DER, \texttt{EndDeviceControl} instances do not target specific hardware controls. To check if two events supersede we need only check if they are active at the same time, and then use their primacy and creation time to determine which supersedes which.

Once again, the interface in Figure 6.22 ensures created responses are valid, where created responses require additional information from the supplied \texttt{SEDevice} instance. 

\subsubsection{Messaging}
The Messaging function set schedule differs greatly from the others, in that multiple \texttt{TextMessage} events can be active at once. For that reason, the implementation remains the same, but without any tracking of superseded events, and slightly different possible response status values. 

\subsubsection{Pricing}
The Pricing function is very much similar to DER and DRLC. One difference is that a Pricing event requires both the \texttt{TariffProfile} resource, and the \texttt{RateComponent} resource. Together, these form the "Program" of the event. "Pricing clients shall support at least one RateComponent instance for each TarifProfile." and "Pricing servers SHALL provide at most one active TimeTariffInterval per rate component." indicate this \cite{IEEE2030.5}.

Therefore, we use the provided \texttt{RateComponent} resource to determine the program MRID, and the provided \texttt{TariffProfile} to determine the primacy of the \texttt{TimeTariffInterval} resource. 

By that measure, a \texttt{TimeTariffInterval} event supersedes another if their active times overlap, and they belong to the same rate component.

\subsubsection{Flow Reservation}
The Flow Reservation function set contains an Event resource (\texttt{FlowReservationResponse}), and it contains a response for that Event, \texttt{FlowReservationResponseResponse}. However, it does not contain an Event program, nor does the specification provide instructions for under what circumstances clients should send \texttt{FlowReservationResponseResponse}, and with what response status.

IEEE 2030.5 Table 27 details response types by function set, and the Flow Reservation function set is not at all present. Furthermore, IEEE 2030.5 is unclear on under what circumstances \texttt{FlowReservationResponse} events are permitted to overlap, and when they should be superseded. 

Whilst we could implement a Flow Reservation schedule with minimal assumptions, it's interface and behaviour would differ greatly from all the other schedules. It would defer to the client supplied callback in all cases, and require them to manually specify every response. Unlike every other schedule, it cannot some program resource type.

If one were to implement the FLow Reservation schedule with a specific use case in mind, it would be a straight forward implementation, and a great deal of existing code in our client library could be reused. For that reason, we do not provide an implementation for this schedule, and instead leave it to library users to implement as required. We have, nonetheless, provided them with an ample resource for developing an IEEE 2030.5 event schedule, our codebase.

\subsection{Logging}
Our client library exposes log messages under a generic logging facade. We use industry standard log levels, \texttt{FATAL, ERROR, WARN, INFO, DEBUG} and \texttt{TRACE}. To accomplish this we use the \texttt{log} crate, developed by the Rust foundation \cite{logcrate}. The logs we create can therefore be attached to any given log implementation or logging frontend, whatever is most suitable for the users of the library.

As many parts of the client library run in the background (Polling, notification server, event schedule) logging is, in many cases the only way to discern that an error has occurred, and that the client has recovered. 

Situations that result in a \texttt{WARN}, or an \texttt{ERROR} log include:

\begin{itemize}
    \item When a regularly polled resource could not be retrieved.
    \item If there is a mismatch between the status of an event in the schedule, and a copy retrieved from a server (and then fed into the schedule).
    \item If an incoming Notification server request or connection could not be handled.
\end{itemize}

Situations that result in a \texttt{INFO} log include:

\begin{itemize}
    \item When a resource is retrieved, from polling or otherwise.
    \item When a POST or PUT request is successful.
    \item When jobs that run in the background shutdown / cleanup (Schedules, Servers).
\end{itemize}

\subsection{Testing}
This client library has been built alongside tests with the goal to maximise test coverage. When running LLVM source-based coverage on \texttt{sep2\_client}, the \texttt{grcov} report claims we have 71.11\% coverage, or 1297 \slash 1824 lines of code covered by tests \cite{grcov} \cite{llvmcov}. 

In section 7.6 we discuss future improvements to testing.

\subsubsection{Mock Server}
With the goal of testing the client's ability to make HTTP requests, we required a way to mock an IEEE 2030.5 server. For this, we implemented a 'dumb' IEEE 2030.5 server that produces hardcoded resources and responses for specific inputs. This test server follows a near identical implementation to that of the Subscription / Notification mechanism. We use this test server to ensure functions that make HTTP requests fail and succeed as expected, and that resource polling retrieves the correct number of resources over a given time period. 

We also use this server to conduct system tests. These system tests follow the examples outlined in IEEE 2030.5 Annex C, currently only testing the core client functionality.

\subsubsection{Subscription / Notification}
In order to send notifications to clients, IEEE 2030.5 need to operate a client capable of making HTTP POST requests. In our client library, a \texttt{Client} instance is separate from a \texttt{ClientNotifServer} instance, meaning our testing process is straight-forward - we make requests to the notification server using our client. 

Our tests ensure that a client interacting with the server is capable of receiving HTTP POST requests, and that the expected response is received. We also implicitly test that our notification server does not crash during regular use.

\subsubsection{Event Schedules}
As each schedule for each function set behaves differently, they are tested separately. For each schedule we create a set of of unique events that each last several seconds, and compare the output on the given callback with the expected output. 

Cases we test include:

\begin{itemize}
    \item Basic sequential execution of events.
    \item Cancelling \& superseding events in progress.
    \item Cancelling \& superseding events before they start.
    \item Ensuring events superseded by cancelled events are rescheduled.
    \item Ensuring Events with different primacy values supersede as required.
    \item Ensuring DER events with differing controls do not supersede.
    \item Ensuring TextMessages do not supersede at all.
    \item Ensuring TimeTariffIntervals from different RateComponents do not supersede one another.
\end{itemize}

\subsubsection{Security}
During development, we maintained a local certificate authority via the tool \texttt{mkcert} and used it for testing \cite{mkcert}. However, this tool is not capable of producing certificates that match those required by IEEE 2030.5

In order to properly test our Security function set, we required TLS certificates as close as possible to those used in the real world; certificates that include all the relevant X509 extensions, and are generated using the specified elliptic curve, and are compatible with the mandatory cipher suite. For this reason, we consult the SunSpec Alliance, who provide free IEE 2030.5 test certificates upon request. As part of this thesis we have requested certificate packages for both our client, and test server, and have tested them when communicating resources, and our interface for parsing and validating X509 certificates.

However, these certificates do not provide us a way with interacting with any publicly accessible IEEE 2030.5 test servers. For that, we'll require test certificates from Energy Queensland, as discussed in section 7.6.









