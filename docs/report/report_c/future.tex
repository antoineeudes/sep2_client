\chapter{Evaluation \& Future Work}\label{ch:future}
Despite all we've accomplished during this thesis, there are many features and improvements we haven't been able to implement purely due to time constraints.
Furthermore, we've been able to identify some flaws in our existing design - potential pain points for developers using our library.

In this chapter we'll compare our implementation to an existing solution, and discuss it's weaknesses and how we plan to improve them. Through this, and our released project, we provide a plan for any and all future work.

\section{Comparison with the EPRI IEEE 2030.5 Client}
We'll first provide a reference point for our progress on this thesis project by comparing it to that of the EPRI IEEE 2003.5 client library, implemented in C.
This library is the oldest, and most popular, open-source implementation of the client protocol.

\begin{table}[h]
	\centering
	\begin{tabular}{llll}
		\toprule
		\textbf{Feature} & \textbf{sep2\_common + sep2\_client} & \textbf{EPRI 2030.5}\\
		\midrule
		XML Resource Serialisation \& Deserialisation & Yes & Yes \\
		EXI Resource Serialisation \& Deserialisation & No  & Yes \\
		DNS-SD                                        & No  & Yes \\
		TLS via OpenSSL                               & Yes  & Yes \\
		Resource Scheduled Polling                    & Yes & Yes \\
		Subscription / Notification Mechanism         & Yes & No \\
		DER Event Scheduler                           & Yes & Yes \\
		DRLC Event Scheduler                          & Yes & No \\
		Pricing Event Scheduler                    	  & Yes & No \\
		Messaging Event Scheduler                     & Yes & No \\
		Flow Reservation Event Scheduler              & No  & Yes \\
		Scheduler Time Offset                         & Yes & No \\
		Global Time Offset                            & Yes & Yes \\
		CSIP-AUS Extensions                           & Yes & No \\
		QualityLogic Formal IEEE 2030.5 Testing       & No  & Yes \\
		\bottomrule
	\end{tabular}
	\caption{Table comparing \texttt{sep2\_common + sep2\_client} and the EPRI IEEE 2030.5 Client.}
	\label{tab:comparsiontable}
\end{table}

Table 7.1 shows a comparison of features and functionality between our implementation, and EPRI's.

Of note is that the EPRI implementation uses minimal third-party libraries, where the security and reliability of required standards (HTTP, XML) is unlikely to have been tested as extensively as the popular open-source libraries used in our implementation.

Of note is that our common and client library do not include implementations for DNS-SD and EXI resource serialisation \& deserialisation. In sections 5.2 and 5.3 we discuss the reasoning behind this. 

In terms of Event function sets, our client has a more complete implementation. We provide library users with black-box schedulers handling DER, Messaging, Pricing, and Demand Response and Load Control events. The EPRI C implementation only includes a schedule for Distributed Energy Resources. The same goes for applying Time resources at a schedule level, EPRI provides no way to have different schedules use different time resources.

Importantly, EPRI's implementation does NOT include a subscription / notification mechanism, the resource retrieval method mandated as part of CSIP. \cite{20305workshop}. 

However, EPRI's implementation has the benefit of having undergone formal testing provided by QualityLogic, which is a paid service. Due to the cost of the service, it is unlikely our implementation will have the opportunity to undergo the same testing.

Finally, our implementation has the benefit of being written in a memory safe language, safe Rust. The EPRI implementation is written in C, where memory safety is not proven by the compiler.

\section{EXI Serialisation \& Deserialisation}
Going forward, we must explore how EXI support can be added to the common library. It's likely that it would be implemented alongside a rewrite / redesign of \texttt{SEPSerde}, such that that the sole library could wrap an EXI library, and an XML library, and produce both as required.
Though this EXI library could be implemented using FFI to a C library, there are complete implementations of EXI parsers and writers in modern languages, and it would be more appropriate to use those as reference implementations for a memory safe fully Rust EXI library. \cite{exijs}

\section{DNS-SD}
Although we've deemed this feature not wholly necessary for this iteration of the client, it is required for full IEEE 2030.5 adherence, and as such we must explore ways to implement it going forward. 

Whilst we could implement this from scratch using just Rust standard library UDP sockets, the open-source tool \texttt{Avahi} provides DNS-SD on Linux. There also exists a tool \texttt{xmDNS-Avahi} that provides an \texttt{xmDNS} server, required by IEEE 2030.5, by modifying \texttt{Avahi}. Furthermore, \texttt{xmDNS-Avahi} cites IEEE 2030.5 as a motivation for requiring an \texttt{xmDNS} server. 
It's therefore likely wrapping this library using Rust FFI would be the most appropriate approach. \cite{avahi} \cite{xmdnsavahi} 

\section{Rust Async Traits}
As of this report, the stable branch of the Rust compiler does not support 'Return Position Impl Trait' (RPIT) in traits (RPITIT). It is simply not supported by the type system \cite{rustRPITIT}.

RPIT is Rust's implementation of existentially quantified types. Functions using RPIT simply return an opaque type that implements a specific trait. e.g. \texttt{fn foo() -> impl Display} is a function that returns some type that can be displayed.

This functionality is necessary in expressing async Rust at the type-level. In Rust, async functions return state machines, types that implement the 'Future' trait. However, these state machines are auto-generated by the compiler and therefore require the use of RPIT to return. Therefore, the async keyword is simply syntactic sugar for \texttt{impl Future<Output = T>}, where T is the final value of the state machine.

Our implementation defines a trait for each of the possible callback types. We want library users to be able to supply asynchronous callbacks, and as such, we require RPITIT.

Currently, there is a popular workaround to this that involves utilizing Rust's dynamic dispatch to heap allocate, and then perform type erasure on the future before returning it, as to allow the function to return a concrete type. This workaround is achieved by having the \texttt{async\_trait} crate generate the necessary code, although it could be accomplished by hand also \cite{asynctrait}. 

This has the obvious downside of incurring an unnecessary heap allocation every time an async function in a trait is called. In our library this is whenever a user defined callback is called, or when an event is added to a schedule.

Fortunately, with the release of the Rust compiler v1.75 on the 28th of December 2023, RPITIT will be stable, and therefore so will async functions in traits \cite{rust175}. 

This comes with a caveat. When async trait functions are declared but not defined, there is no way to infer what bounds on the return type can be relaxed. More specifically, the compiler cannot infer that all implementations of that trait function return a type that can be sent or referenced across thread boundaries (the Rust Send \& Sync traits). The solution to this is in active development, and is referred to as "minimal associated return type notation" \cite{sendboundproblem}.

The Tokio runtime is a 'work-stealing' executor. In practice, this means Rust futures we return must implement the \texttt{Send} trait, this means they can be sent across thread boundaries. Since we cannot express this using an async function in a trait, we would fallback on what would be the desugared syntax alternative, \texttt{impl Future<Output = T> + Send}. This results in a marginally less ergonomic interface, as implementers of the trait now need to wrap their code in a async block themselves. However, this is still an improvement on the performance overhead and additional dependency that we require for the current workaround.

\section{Native Rust TLS}
In section 6.2.3 we discussed how make use of the available OpenSSL Rust bindings to implement the security function set, and so far this has been sufficient. However, we note the 19 reported CVEs in OpenSSL in 2023 alone as a slight cause for alarm \cite{OpensslCVE}. 

However, there exists a project called \texttt{rustls} that eventually aims to compete with OpenSSL by providing a Rust native implementation of TLS for server and client verification, and bulk encryption \cite{rustls}, leveraging the memory safety guarantees of Rust. \texttt{rustls} uses the \texttt{ring} crate, which provides (almost) native Rust cryptography algorithms \cite{ring}. 
In early benchmarks, \texttt{rustls} is shaping up to be more performant and more memory efficient than OpenSSL. \cite{rustlsperf}

Currently, the \texttt{ring} crate does not support Authenticated Encryption using CCM, as required by IEEE 2030.5, stalling progress on being able to use \texttt{rustls}. As part of our library release, we will inquire with the status of this implementation, and what further work is required to add the functionality to \texttt{ring}. Currently, progress on this feature in ring has stalled, and there may be avenues for us to contribute to ring directly \cite{ringccmpr} \cite{ringccmissue}.

\section{HTTP Implementation Improvements}
Whilst we use the \texttt{hyper} client as part of our implementation, and not the more commonly used wrapper around it, \texttt{reqwest}, we lose a great deal of functionality that is necessary for both ergonomics, and IEEE 2030.5 requirements \cite{reqwest}. 

One such crucial example is the ability to handle HTTP redirects without having to implement it ourselves.
With the recent release of \texttt{hyper 1.0}, this problem is exacerbated, with the library requiring more of the lower level details be handled in our implementation, as it aims to provide a more generic, less opinionated, HTTP implementation.   

\texttt{reqwest} supports TLS using either OpenSSL (via the \texttt{native\_tls} crate), or \texttt{rustls}. However, when used with OpenSSL it does not expose a way to specify the cipher-list used. We require this functionality to force the use of the IEEE 2030.5 cipher suite. One workaround to this would be to have users of our library modify the OpenSSL source-code, and compile a version that has our cipher suite as the default. This is far from ideal from a usability perspective \cite{reqwestopenssl}.

Aside from this, we do not require any of the extra low-level functionality provided by \texttt{hyper}. Outside of security, \texttt{reqwest} is the library better suited to our use case.

Therefore, to use \texttt{reqwest} we require that \texttt{native\_tls} and \texttt{hyper} expose a way to modify the cipher-suite used. As \texttt{native\_tls} is designed to be cross-platform, and OpenSSL is only used on Linux, this seems like an unlikely addition.

Alternatively, to use \texttt{reqwest} we require that \texttt{rustls} support the IEEE 2030.5 cipher suite, which first depends on progress on \texttt{ring}.

In the meantime, we will continue to use \texttt{hyper}, and make users of our library aware of the current deficiencies in the library as a result, using GitHub issues.
Furthermore, we are very much motivated to look into the possibility of contributing to \texttt{rustls}, \texttt{ring}, \texttt{reqwest} or \texttt{native\_tls}, and implementing the required functionality ourselves.


\section{Maintainability}
With the goal of this thesis to produce an IEEE 2030.5 client library implementation that can be released under open-source licenses, we develop our implementation with a focus on ensuring it can be maintained into the future. 

As of present, this takes the form of:

\begin{itemize}
    \item Generated 'rustdoc' documentation, as is preferred by the Rust open-source community.
    \item Thorough internal documentation, with explicit references to IEEE 2030.5 to justify behaviours.
    \item Example client binary source-code, showing the DER function set and event scheduler in use under the direct / individual model.
    \item GitHub project management, detailing planned enhancements and broken functionality as GitHub issues.
    \item The modular nature of our implementation, with responsibilities delegated to different Rust crates, and compile flags.
\end{itemize}

In order to ensure our client is maintainable into the future, we will:

\begin{itemize}
    \item Produce additional full client binary examples, showing usage of the subscription / notification model, and other event schedules.
    \item Develop function usage examples, and include them as part of the rustdoc.
    \item Respond to and engage with library users, and their feedback. Working with users to fix issues they report.
    \item Upload our implementation to the \texttt{crates.io} package manager, which will host our rustdoc, and handle version releases. This will also allow us to have a singly sourced README for both github and rustdoc. 
\end{itemize}

\section{Testing}
As it stands, our client and common library are reasonably well-tested, with code coverage of 63.79\% \footnote{A figure of 73\% code coverage was previously given in the seminar, however this figure included the tests as part of the coverage, and was therefore incorrect.} when measured by lines of code. Keeping in mind, a large portion of this is compile-time generated code that has already been tested, we would nonetheless like to improve this going forward by:

\begin{itemize}
	\item Testing our resource serialisation against all remaining example XML in Annex C.
	\item Testing our implementation against all remaining example system tests in Annex C.
	\item Testing automated schedule responses are sent as required (only client output is tested currently).
	\item Improving coverage wherever possible.
\end{itemize}

Furthermore, we would like to test our implementation against production-ready IEEE 2030.5 servers. There are currently two candidates against which this testing can be done, the \texttt{GridAPPS} IEEE 2030.5 server implementation, and the publicly accessible IEEE 2030.5 Test API hosted by Energy Queensland \cite{sep2clienthandbook} \cite{gridapps}. Both of these servers are poorly advertised, and were discovered very late into this thesis.

Going forward, we will investigate if and how these servers can be used to further test our implementation. Of note, is that the Energy Queensland test server accepts certificate signing requests, and thus gaining access to that server is very much possible.

\section{Authenticating Notification / Subscription}
As of present, a \texttt{ClientNotifServer} can be instantiated without TLS. This is done as to not restrict library users to performing TLS termination at the application, and allowing them to run the notification server behind a reverse proxy or load balancer, such as \texttt{nginx} or \texttt{Apache}. 
However, this poses some difficulties when paired with \texttt{mTLS}. It is not immediately obvious how client notification servers will perform authentication of incoming requests. This was an issue also encountered  by BSGIP, and discussed in their report "On the implementation and publishing of operating envelopes" \cite{envoyclient}.

It's likely that library users will want to define this authentication  procedure themselves. For that reason, we will likely need to discuss with them how they wish to implement this functionality, and use that to determine if and how it can be implemented into our client in a generic way.

\section{Error Handling}
One potential pain point in our current implementation is our usage of opaque error types. All errors returned by our interface resolve to a single Error type, provided by the \texttt{anyhow} crate. The exception to this is are parts of the core client functionality interface, as we discussed in 6.2.4.

This design simplifies our error handling, but limits the potential error cases users of our library can handle. Since we are unable to envisage exactly how users of our library might want to handle errors, it would be more appropriate to use transparent error types that provide more insight into why some operations failed.

Fortunately, our interfaces expose few very functions that return an error. Many error cases occur running in the background. Consequently, improving error handling would require minimal changes, yet careful consideration.

One case where improvements could be easily made are user-defined callbacks. Currently our implementation only calls the poll and notification callbacks when a valid resource could be deserialised, it does not allow the library user to specify a specific behaviour when an error occurs. We could change this to provide users with the \texttt{Result} enum directly, and allow them to handle the error case however they wish. This change makes more sense to implement once we provide more transparent error types.   

\section{Benchmarking \& Profiling}
We currently have no data, or frame of reference, for the performance of the client. 

Going forward, it would be extremely beneficial to perform some form of profiling on an instance of the client in a production context. Particularly, we are interested in what, if any parts of the code are responsible for excessive heap allocations, or uncessecarily complex computations that may impact performance.
We are also interested in the memory footprint of the client over an extended period of time, to ensure that memory is being freed appropriately. For example, that the schedule garbage collection process is occurring. 

Furthermore, we would like to know what parts of our implementation run most frequently and take the longest time to complete, the 'hot' function calls that we would need to optimise further. 

It's likely these will be the functionality responsible for serialising \& deserialising resources, and will further incentivise us to rewrite \texttt{SEPSerde} from scratch.

It would also be sensible to conduct benchmarks of the client when completing a fixed workload, such as several completing several requests simultaneously, and then compare those benchmarks to that of the EPRI C implementation.

