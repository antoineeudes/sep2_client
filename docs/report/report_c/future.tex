\chapter{Evaluation \& Future Work}\label{ch:future}
Despite all we've accomplished during this thesis, there are many features and improvements we haven't been able to implement purely due to time constraints, as well as functionality whose implementation is not entirely within our control.
Furthermore, we've been able to identify some flaws in our existing design, potential pain points for developers using our library, and unnecessary restrictions.

In this chapter we'll compare our implementation to existing solutions.
We'll discuss it's weaknesses and how we plan to improve them, and we'll provide a plan for any and all future work.

\section{Comparison with the EPRI IEEE 2030.5 Client}
We'll first provide a reference point for our progress on this thesis project by comparing it to that of the EPRI IEEE 2003.5 client library, implemented in C.
This library is the oldest, and most popular open-source implementation of the client protocol.

\begin{table}[h]
	\centering
	\begin{tabular}{llll}
		\toprule
		\textbf{Feature} & \textbf{sep2\_common + sep2\_client} & \textbf{EPRI 2030.5}\\
		\midrule
		XML Resource Serialisation \& Deserialisation & Yes & Yes \\
		EXI Resource Serialisation \& Deserialisation & No  & Yes \\
		DNS-SD                                        & No  & Yes \\
		TLS via OpenSSL                               & Yes  & Yes \\
		Resource Scheduled Polling                    & Yes & Yes \\
		Subscription / Notification Mechanism         & Yes & No \\
		DER Event Scheduler                           & Yes & Yes \\
		DRLC Event Scheduler                          & Yes & No \\
		Pricing Event Scheduler                    	  & Yes & No \\
		Messaging Event Scheduler                     & Yes & No \\
		Flow Reservation Event Scheduler              & No  & Yes \\
		Scheduler Time Offset                         & Yes & No \\
		Global Time Offset                            & Yes & Yes \\
		CSIP-AUS Extensions                           & Yes & No \\
		QualityLogic Formal IEEE 2030.5 Testing       & No  & Yes \\
		Memory Safety Guarantees                      & Yes & No \\
		\bottomrule
	\end{tabular}
	\caption{EPRI IEEE 2030.5 Client comparison table}
	\label{tab:comparsiontable}
\end{table}

Table 7.1 shows a comparison of features, functionality, and safety and correctness properties between our implementation, and EPRI's.

Of note is that our client library does not include an implementation for DNS-SD and EXI Resource Serialisation \& deserialisation. In sections 5.2 and 5.3 we discuss the reasoning behind this.  

In terms of Event function sets, our client has a more complete implementation. We provide library users with black-box schedulers handling DER, Messaging, Pricing, and Demand Response and Load Control events. The EPRI C implementation only includes a schedule for Distributed Energy Resources. The same goes for applying Time resources at a schedule level, EPRI provides no way to have different schedules use different time resources, as would be required under certain circumstances.

Importantly, EPRI's implementation does NOT include a subscription / notification mechanism, the resource retrieval method mandated as part of CSIP (American). \cite{20305workshop}

However, EPRI's implementation has the benefit of having undergone formal testing provided by QualityLogic, which is a paid, service. Due to the cost of the service, it is unlikely our implementation will ever have the opportunity to undergo the same testing.

Finally, our implementation has the benefit of being written in a memory safe language, safe Rust. The EPRI implementation is written in C, where memory safety must be checked and proven manually. 

\section{Rust Async Traits}
As of this report, the stable branch of the Rust compiler does not support 'Return Position Impl Trait' (RPIT) in traits (RPITIT). It is simply not supported by the type system. \cite{rustRPITIT}

RPIT is Rust's implementation of existentially quantified types. Functions using RPIT simply return some type that implements the given trait. For example \texttt{fn foo() -> impl Display} is a function that returns some type that can be displayed.

This functionality is necessary in expressing async Rust at the type-level. In Rust, async functions return state machines, types that implement the 'Future' trait. However, these state machines are auto-generated by the compiler and therefore require the use of RPIT to return. Therefore, the async keyword is simply syntactic sugar for \texttt{impl Future<Output = T>}, where T is the final value of the state machine.

Our implementation defines a trait for each of the possible callback types. We want library users to be able to supply asynchronous callbacks, and as such, we require RPITIT.

Currently, there is a popular workaround to this that involves utilizing Rust's dynamic dispatch to heap allocate, and then perform type erasure on the future before returning it, as to allow the function to return a concrete type. This workaround is achieved by having the \texttt{async\_trait} crate generate the necessary code, although it could be accomplished without. \cite{asynctrait}

This has the obvious downside of incurring an unnecessary heap allocation every time an async function in a trait is called. In our library this is whenever a user defined callback is called, or when an event is added to a schedule.

Fortunately, with the release of the Rust compiler v1.75 on the 28th of December 2023, RPITIT will be stable, and therefore so will async functions in traits. \cite{rust175}

This comes with a caveat. When async trait functions are declared but not defined, there is no way to infer what bounds on the return type can be relaxed. More specifically, the compiler cannot infer that all implementations of that trait function return a type that can be sent or referenced across thread boundaries (the Rust Send \& Sync traits). The solution to this is in active development, and is referred to as "minimal associated return type notation" \cite{sendboundproblem}.

The Tokio runtime is a 'work-stealing' executor. In practice, this means Rust futures we return must implement the \texttt{Send} trait, and can be sent across thread boundaries. Since we cannot express this using an async function in a trait, we would fallback on what would be the desugared syntax alternative, \texttt{impl Future<Output = T> + Send}. This results in a marginally less ergonomic interface, as implementers of the trait now need to wrap their code in a async block themselves. However, this is still superior to the performance overhead and additional dependency that we require for the current workaround.

\section{Native Rust TLS}
In section 6.2.3 we discussed how make use of the available \texttt{OpenSSL} Rust bindings to implement the security function set, and so far this has been sufficient. However, we note the 19 reported CVEs in \texttt{OpenSSL} in 2023 alone as a cause for alarm. \cite{OpensslCVE}

However, there exists a project called \texttt{rustls} that eventually aims to compete with \texttt{OpenSSL} by providing a Rust native implementation of TLS for server and client verification, and bulk encryption \cite{rustls}. \texttt{rustls} leverages the \texttt{ring} crate, which provides (almost) native Rust cryptography algorithms \cite{ring}. 
In early benchmarks, \texttt{rustls} is shaping up to be more performant and more memory efficient than \texttt{OpenSSL}.

Currently, the \texttt{ring} crate does not support Authenticated Encryption using CCM, as required by IEEE 2030.5, stalling progress on being able to use \texttt{rustls}. As part of our library release, we will inquire with the status of this implementation, and what further work is required to add the functionality to \texttt{ring}. Currently, progress on this feature in ring has stalled, and there may be avenues for us to contribute to ring directly \cite{ringccmpr} \cite{ringccmissue}.


\section{Maintainability}
With the goal of this thesis to produce an IEEE 2030.5 client library implementation that can be released under open-source licenses, we develop our implementation with a focus on ensuring it can be maintained into the future. 

As of present, this takes the form of:

\begin{itemize}
    \item Generated 'rustdoc' documentation, as is preferred by the Rust open-source ecosystem.
    \item Reasonable internal documentation, with explicit references to IEEE 2030.5 to justify behaviours.
    \item Example client binary source-code, showing the DER function set and event scheduler in use under the direct / individual model.
    \item GitHub project management, detailing planned enhancements and broken functionality as issues.
    \item The modular nature of our implementation; functionality delegated to different Rust crates.
\end{itemize}

In order to ensure our client is maintainable into the future, we will:

\begin{itemize}
    \item Produce additional full client binary examples, showing usage of the subscription / notification model, and other event schedules.
    \item Develop function usage examples, and include them as part of the rustdoc.
    \item Respond to and engage with library users, and their feedback, including attempting to fix any and all issues they encounter.
\end{itemize}

\section{Testing}
As it stands, our client and common library are reasonably well-tested, with code coverage of 73.72\% when measured by lines of code. We would like to improve this going forward by:

\begin{itemize}
	\item Testing our resource serialisation against all remaining example XML in Annex C.
	\item Testing our implementation against all remaining example system tests in Annex C.
	\item Testing automated schedule responses are sent as required (only client output is tested currently).
	\item Improving coverage wherever possible.
\end{itemize}
ensuring all resources are serialised correctly.

Furthermore, we would like to test our implementation against production-ready IEEE 2030.5 servers. There are currently two candidates against which this testing can be done, the \texttt{GridAPPS} IEEE 2030.5 server implementation, and the publicly accessible IEEE 2030.5 Test API hosted by Energy Queensland \cite{sep2clienthandbook} \cite{gridapps}. Both of these servers are not very well advertised, and were discovered very late into this thesis.

Going forward, we will investigate if and how these servers can be used to further test our implementation.

\section{Authenticating Notification / Subscription}
As of present, a \texttt{ClientNotifServer} can be instantiated without TLS. This is done as to not restrict library users to performing TLS termination at the application, and allowing them to run the notification server behind a reverse proxy or load balancer, such as \texttt{nginx} and \texttt{Apache}. 
However, this poses some difficulties when paired with \texttt{mTLS}. It is not immediately obvious how client notification servers will perform authentication of incoming requests. This was an issue also encountered  by BSGIP, and discussed in their report "On the implementation and publishing of operating envelopes" \cite{envoyclient}.

It's likely that library users will want to define this authentication  procedure themselves. For that reason, we will likely need to discuss with them how they wish to implement this functionality, and use that to determine if and how it can be implemented into our client in a generic way.

\section{Error Handling}
One potential pain point in our current implementation is our usage of opaque error types. All errors returned by our interface resolve to a single Error type, provided by the \texttt{anyhow} crate. The exception to this is are parts of the core client functionality interface, however, even in that case many error cases resolve to a single Error type. 

This simplifies our internal error handling, but limits the potential error cases users of our library can handle. Since we are unable to envisage exactly how users of our library might want to handle errors, it would be more appropriate to use transparent error types that provide more insight into why some operations failed.

Fortunately, our interfaces expose few very functions that return an error. Many error cases occur running in the background. As such, improving error handling would require minimal changes.

\section{Benchmarking \& Profiling}
We currently have no data, or frame of reference, for the performance of the client. 

Going forward, it would be extremely beneficial to perform some form of profiling on an instance of the client in a production context. Particularly, we are interested in what, if any parts of the code are responsible for excessive heap allocations that may impact performance.
We are also interested in the memory footprint of the client over an extended period of time, to ensure that memory is being freed appropriately. For example, that schedule garbage collection is occurring. 

Furthermore, we would like to know what parts of our implementation that run most frequently and take the longest time to complete, the 'hot' function calls that we would need to optimise further. It's likely these will be the functionality responsible for serialising \& deserialising resources, and will further incentivise us to rewrite \texttt{SEPserde} from scratch.

It would also be sensible to conduct benchmarks of the client when completing a fixed workload, such as several completing several requests simultaneously, and then compare those benchmarks to that of the EPRI C implementation.






